[
  {
    "url": "https://paperswithcode.com/dataset/unsw-nb15",
    "name": "UNSW-NB15",
    "full_name": "UNSQ-NB15",
    "homepage": "https://www.unsw.adfa.edu.au/unsw-canberra-cyber/cybersecurity/ADFA-NB15-Datasets/",
    "description": [
      "**UNSW-NB15** is a network intrusion dataset. It contains nine different attacks, includes DoS, worms, Backdoors, and Fuzzers. The dataset contains raw network packets. The number of records in the training set is 175,341 records and the testing set is 82,332 records from the different types, attack and normal.",
      "Source: [Evaluation of Adversarial Training on Different Types of Neural Networks in Deep Learning-based IDSs](https://arxiv.org/abs/2007.04472)",
      "Image Source: [https://www.unsw.adfa.edu.au/unsw-canberra-cyber/cybersecurity/ADFA-NB15-Datasets/](https://www.unsw.adfa.edu.au/unsw-canberra-cyber/cybersecurity/ADFA-NB15-Datasets/)",
      "Paper: [UNSW-NB15: a comprehensive data set for network intrusion detection systems](https://doi.org/10.1109/MilCIS.2015.7348942)"
    ],
    "paper": {
      "title": "UNSW-NB15: a comprehensive data set for network intrusion detection systems (UNSW-NB15 network data set)",
      "url": "https://doi.org/10.1109/MilCIS.2015.7348942"
    },
    "introduced_date": "2015-11-01",
    "warning": null,
    "modalities": [
      "Tabular"
    ],
    "tasks": [
      {
        "task": "Intrusion Detection",
        "url": "https://paperswithcode.com/task/intrusion-detection"
      },
      {
        "task": "Synthetic Data Generation",
        "url": "https://paperswithcode.com/task/synthetic-data-generation"
      },
      {
        "task": "Network Intrusion Detection",
        "url": "https://paperswithcode.com/task/network-intrusion-detection"
      }
    ],
    "languages": [
      "Russian"
    ],
    "variants": [
      "UNSW-NB15"
    ],
    "num_papers": 147,
    "data_loaders": [
      {
        "url": "https://www.kaggle.com/datasets/dhoogla/unswnb15",
        "repo": "https://github.com/Kaggle/kaggle-api",
        "frameworks": []
      }
    ]
  },
  {
    "url": "https://paperswithcode.com/dataset/cry-wolf",
    "name": "Cry Wolf",
    "full_name": "",
    "homepage": "https://uncw-hfcs.github.io/ids-simulator-analysis/",
    "description": [
      "**Cry Wolf** is a dataset for cyber security analysis tasks. It is an open-access dataset of 73 true and false Intrusion Detection System (IDS) alarms derived from real-world examples of \"impossible travel\" scenarios."
    ],
    "paper": {
      "title": "Cry Wolf: Toward an Experimentation Platform and Dataset for Human Factors in Cyber Security Analysis",
      "url": "https://paperswithcode.com/paper/cry-wolf-toward-an-experimentation-platform"
    },
    "introduced_date": "2020-02-24",
    "warning": null,
    "modalities": [],
    "tasks": [],
    "languages": [],
    "variants": [
      "Cry Wolf"
    ],
    "num_papers": 1,
    "data_loaders": []
  },
  {
    "url": "https://paperswithcode.com/dataset/ton-iot",
    "name": "ToN_IoT",
    "full_name": "",
    "homepage": "https://ieee-dataport.org/documents/toniot-datasets",
    "description": [
      "The **TON_IoT** datasets are new generations of Internet of Things (IoT) and Industrial IoT (IIoT) datasets for evaluating the fidelity and efficiency of different cybersecurity applications based on Artificial Intelligence (AI). The datasets have been called \u2018ToN_IoT\u2019 as they include heterogeneous data sources collected from Telemetry datasets of IoT and IIoT sensors, Operating systems datasets of Windows 7 and 10 as well as Ubuntu 14 and 18 TLS and Network traffic datasets. The datasets were collected from a realistic and large-scale network designed at the IoT Lab of the UNSW Canberra Cyber, the School of Engineering and Information technology (SEIT), UNSW Canberra @ the Australian Defence Force Academy (ADFA).",
      "The datasets were gathered in a parallel processing to collect several normal and cyber-attack events from IoT networks. A new testbed was developed at the IoT lab to connect many virtual machine, physical systems, hacking platforms, cloud and fog platforms, IoT and IIoT sensors to mimic the complexity and scalability of industrial IoT and Industry 4.0 networks.",
      "Different hacking techniques, such as DoS, DDoS and ransomware against, were launched against web applications, IoT gateways and computer systems across the IIoT network."
    ],
    "paper": {
      "title": "Federated TON_IoT Windows Datasets for Evaluating AI-based Security Applications",
      "url": "https://paperswithcode.com/paper/federated-ton-iot-windows-datasets-for"
    },
    "introduced_date": "2020-10-04",
    "warning": null,
    "modalities": [],
    "tasks": [
      {
        "task": "Speech Synthesis - Gujarati",
        "url": "https://paperswithcode.com/task/speech-synthesis-gujarati"
      }
    ],
    "languages": [],
    "variants": [
      "ToN_IoT"
    ],
    "num_papers": 7,
    "data_loaders": []
  },
  {
    "url": "https://paperswithcode.com/dataset/analytic-provenance",
    "name": "Analytic Provenance",
    "full_name": "",
    "homepage": "https://research.arch.tamu.edu/analytic-provenance/datasets/",
    "description": [
      "**Analytic provenance** is a data repository that can be used to study human analysis activity, thought processes, and software interaction with visual analysis tools during exploratory data analysis. It was collected during a series of user studies involving exploratory data analysis scenario with textual and cyber security data. Interactions logs, think-alouds, videos and all coded data in this study are available online for research purposes.",
      "Analysis sessions are segmented in multiple sub-task steps based on user think-alouds, video and audios captured during the studies. These analytic provenance datasets can be used for research involving tools and techniques for analyzing interaction logs and analysis history."
    ],
    "paper": {
      "title": "Analytic Provenance Datasets: A Data Repository of Human Analysis Activity and Interaction Logs",
      "url": "https://paperswithcode.com/paper/analytic-provenance-datasets-a-data"
    },
    "introduced_date": "2018-01-16",
    "warning": null,
    "modalities": [],
    "tasks": [],
    "languages": [],
    "variants": [
      "Analytic Provenance"
    ],
    "num_papers": 1,
    "data_loaders": []
  },
  {
    "url": "https://paperswithcode.com/dataset/ctfw",
    "name": "CTFW",
    "full_name": "",
    "homepage": "https://github.com/kuntalkumarpal/FlowGraph",
    "description": [
      "**CTFW** is a large annotated procedural text dataset in the cybersecurity domain (3154 documents). It is used to generate flow graphs from procedural texts."
    ],
    "paper": {
      "title": "Constructing Flow Graphs from Procedural Cybersecurity Texts",
      "url": "https://paperswithcode.com/paper/constructing-flow-graphs-from-procedural"
    },
    "introduced_date": "2021-05-29",
    "warning": null,
    "modalities": [
      "Texts",
      "Graphs"
    ],
    "tasks": [],
    "languages": [
      "English"
    ],
    "variants": [
      "CTFW"
    ],
    "num_papers": 1,
    "data_loaders": []
  },
  {
    "url": "https://paperswithcode.com/dataset/casie",
    "name": "CASIE",
    "full_name": "",
    "homepage": "https://github.com/Ebiquity/CASIE",
    "description": [
      "### Annotation corpus of cybersecurity event in news articles",
      "The corpus contains 1000 annotation and source files. Our cybersecurity focused on five event types: Databreach, Phishing, Ransom, Discover, and Patch.",
      "More details of the annotation and CASIE's system are in the papers. If you use our data, please cite one of the following papers.",
      "Taneeya Satyapanich, Francis Ferraro, and Tim Finin, \"CASIE: Extracting Cybersecurity Event Information from Text\", InProceedings, Proceeding of the 34th AAAI Conference on Artificial Intelligence, February 2020.",
      "Taneeya Satyapanich, Tim Finin, and Francis Ferraro, \"Extracting Rich Semantic Information about Cybersecurity Events\", InProceedings, Second Workshop on Big Data for CyberSecurity, held in conjunction with the IEEE Int. Conf. on Big Data, December 2019.",
      "Any problems found, please contact taneeya1@umbc.edu."
    ],
    "paper": null,
    "introduced_date": null,
    "warning": null,
    "modalities": [],
    "tasks": [],
    "languages": [],
    "variants": [
      "CASIE"
    ],
    "num_papers": 1,
    "data_loaders": []
  },
  {
    "url": "https://paperswithcode.com/dataset/aiseckg",
    "name": "AISECKG",
    "full_name": "AISecKG: Knowledge Graph Dataset for Cybersecurity Education",
    "homepage": "https://github.com/garima0106/AISecKG-cybersecurity-dataset",
    "description": [
      "Cybersecurity education is exceptionally challenging as it involves learning the complex attacks; tools and developing critical problem-solving skills to defend the systems. For a student or novice researcher in the cybersecurity domain, there is a need to design an adaptive learning strategy that can break complex tasks and concepts into simple representations. An AI-enabled automated cybersecurity education system can improve cognitive engagement and active learning. Knowledge graphs (KG) provide a visual representation in a graph that can reason and interpret from the underlying data, making them suitable for use in education and interactive learning. However, there are no publicly available datasets for the cybersecurity education domain to build such systems. The data is present as unstructured educational course material, Wiki pages, capture the flag (CTF) writeups, etc. Creating knowledge graphs from unstructured text is challenging without an ontology or annotated dataset. However, data annotation for cybersecurity needs domain experts. To address these gaps, we made three contributions in this paper. First, we propose an ontology for the cybersecurity education domain for students and novice learners. Second, we develop AISecKG, a triple dataset with cybersecurity-related entities and relations as defined by the ontology. This dataset can be used to construct knowledge graphs to teach cybersecurity and promote cognitive learning. It can also be used to build downstream applications like recommendation systems or self-learning question-answering systems for students. The dataset would also help identify malicious named entities and their probable impact. Third, using this dataset, we show a downstream application to extract custom-named entities from texts and educational material on cybersecurity."
    ],
    "paper": null,
    "introduced_date": "2023-03-30",
    "warning": null,
    "modalities": [
      "Texts"
    ],
    "tasks": [
      {
        "task": "Knowledge Graphs",
        "url": "https://paperswithcode.com/task/knowledge-graphs"
      },
      {
        "task": "NER",
        "url": "https://paperswithcode.com/task/cg"
      },
      {
        "task": "Ontology Matching",
        "url": "https://paperswithcode.com/task/ontology-matching"
      }
    ],
    "languages": [
      "English"
    ],
    "variants": [
      "AISECKG"
    ],
    "num_papers": 1,
    "data_loaders": [
      {
        "url": "https://github.com/garima0106/AISecKG-cybersecurity-dataset",
        "repo": "https://github.com/garima0106/AISecKG-cybersecurity-dataset",
        "frameworks": [
          "pytorch"
        ]
      }
    ]
  },
  {
    "url": "https://paperswithcode.com/dataset/cicids2017",
    "name": "CICIDS2017",
    "full_name": "Intrusion Detection Evaluation Dataset (CIC-IDS2017)",
    "homepage": "https://www.unb.ca/cic/datasets/ids-2017.html",
    "description": [
      "Intrusion Detection Evaluation Dataset (CIC-IDS2017)",
      "Intrusion Detection Systems (IDSs) and Intrusion Prevention Systems (IPSs) are the most important defense tools against the sophisticated and ever-growing network attacks. Due to the lack of reliable test and validation datasets, anomaly-based intrusion detection approaches are suffering from consistent and accurate performance evolutions.",
      "Our evaluations of the existing eleven datasets since 1998 show that most are out of date and unreliable. Some of these datasets suffer from the lack of traffic diversity and volumes, some do not cover the variety of known attacks, while others anonymize packet payload data, which cannot reflect the current trends. Some are also lacking feature set and metadata.",
      "CICIDS2017 dataset contains benign and the most up-to-date common attacks, which resembles the true real-world data (PCAPs). It also includes the results of the network traffic analysis using CICFlowMeter with labeled flows based on the time stamp, source, and destination IPs, source and destination ports, protocols and attack (CSV files). Also available is the extracted features definition.",
      "Generating realistic background traffic was our top priority in building this dataset. We have used our proposed B-Profile system (Sharafaldin, et al. 2016) to profile the abstract behavior of human interactions and generates naturalistic benign background traffic. For this dataset, we built the abstract behaviour of 25 users based on the HTTP, HTTPS, FTP, SSH, and email protocols.",
      "The data capturing period started at 9 a.m., Monday, July 3, 2017 and ended at 5 p.m. on Friday July 7, 2017, for a total of 5 days. Monday is the normal day and only includes the benign traffic. The implemented attacks include Brute Force FTP, Brute Force SSH, DoS, Heartbleed, Web Attack, Infiltration, Botnet and DDoS. They have been executed both morning and afternoon on Tuesday, Wednesday, Thursday and Friday.",
      "In our recent dataset evaluation framework (Gharib et al., 2016), we have identified eleven criteria that are necessary for building a reliable benchmark dataset. None of the previous IDS datasets could cover all of the 11 criteria. In the following, we briefly outline these criteria:",
      "Complete Network configuration: A complete network topology includes Modem, Firewall, Switches, Routers, and presence of a variety of operating systems such as Windows, Ubuntu and Mac OS X.",
      "Complete Traffic: By having a user profiling agent and 12 different machines in Victim-Network and real attacks from the Attack-Network.",
      "Labelled Dataset: Section 4 and Table 2 show the benign and attack labels for each day. Also, the details of the attack timing will be published on the dataset document.",
      "Complete Interaction: As Figure 1 shows, we covered both within and between internal LAN by having two different networks and Internet communication as well.",
      "Complete Capture: Because we used the mirror port, such as tapping system, all traffics have been captured and recorded on the storage server.",
      "Available Protocols: Provided the presence of all common available protocols, such as HTTP, HTTPS, FTP, SSH and email protocols.",
      "Attack Diversity: Included the most common attacks based on the 2016 McAfee report, such as Web based, Brute force, DoS, DDoS, Infiltration, Heart-bleed, Bot and Scan covered in this dataset.",
      "Heterogeneity: Captured the network traffic from the main Switch and memory dump and system calls from all victim machines, during the attacks execution.",
      "Feature Set: Extracted more than 80 network flow features from the generated network traffic using CICFlowMeter and delivered the network flow dataset as a CSV file. See our PCAP analyzer and CSV generator.",
      "MetaData: Completely explained the dataset which includes the time, attacks, flows and labels in the published paper.",
      "The full research paper outlining the details of the dataset and its underlying principles:",
      "Iman Sharafaldin, Arash Habibi Lashkari, and Ali A. Ghorbani, \u201cToward Generating a New Intrusion Detection Dataset and Intrusion Traffic Characterization\u201d, 4th International Conference on Information Systems Security and Privacy (ICISSP), Purtogal, January 2018",
      "Day, Date, Description, Size (GB)",
      "Monday, Normal Activity, 11.0G",
      "Tuesday, attacks + Normal Activity, 11G",
      "Wednesday, attacks + Normal Activity, 13G",
      "Thursday, attacks + Normal Activity, 7.8G",
      "Friday, attacks + Normal Activity, 8.3G",
      "Victim and attacker networks information",
      "Firewall: 205.174.165.80, 172.16.0.1",
      "DNS+ DC Server: 192.168.10.3",
      "Outsiders (Attackers network)",
      "Kali: 205.174.165.73",
      "Win: 205.174.165.69, 70, 71",
      "Insiders (Victim network)",
      "Web server 16 Public: 192.168.10.50, 205.174.165.68",
      "Ubuntu server 12 Public: 192.168.10.51, 205.174.165.66",
      "Ubuntu 14.4, 32B: 192.168.10.19",
      "Ubuntu 14.4, 64B: 192.168.10.17",
      "Ubuntu 16.4, 32B: 192.168.10.16",
      "Ubuntu 16.4, 64B: 192.168.10.12",
      "Win 7 Pro, 64B: 192.168.10.9",
      "Win 8.1, 64B: 192.168.10.5",
      "Win Vista, 64B: 192.168.10.8",
      "Win 10, pro 32B: 192.168.10.14",
      "Win 10, 64B: 192.168.10.15",
      "MAC: 192.168.10.25",
      "Monday, July 3, 2017",
      "Benign (Normal human activities)",
      "Tuesday, July 4, 2017",
      "Brute Force",
      "FTP-Patator (9:20 \u2013 10:20 a.m.)",
      "SSH-Patator (14:00 \u2013 15:00 p.m.)",
      "Attacker: Kali, 205.174.165.73",
      "Victim: WebServer Ubuntu, 205.174.165.68 (Local IP: 192.168.10.50)",
      "NAT Process on Firewall:",
      "Attack: 205.174.165.73 -> 205.174.165.80 (IP Valid Firewall) -> 172.16.0.10 -> 192.168.10.50",
      "Reply: 192.168.10.50 -> 172.16.0.1 -> 205.174.165.80 -> 205.174.165.73",
      "Wednesday, July 5, 2017",
      "DoS / DDoS",
      "DoS slowloris (9:47 \u2013 10:10 a.m.)",
      "DoS Slowhttptest (10:14 \u2013 10:35 a.m.)",
      "DoS Hulk (10:43 \u2013 11 a.m.)",
      "DoS GoldenEye (11:10 \u2013 11:23 a.m.)",
      "Attacker: Kali, 205.174.165.73",
      "Victim: WebServer Ubuntu, 205.174.165.68 (Local IP192.168.10.50)",
      "NAT Process on Firewall:",
      "Attack: 205.174.165.73 -> 205.174.165.80 (IP Valid Firewall) -> 172.16.0.10 -> 192.168.10.50",
      "Reply: 192.168.10.50 -> 172.16.0.1 -> 205.174.165.80 -> 205.174.165.73",
      "Heartbleed Port 444 (15:12 - 15:32)",
      "Attacker: Kali, 205.174.165.73",
      "Victim: Ubuntu12, 205.174.165.66 (Local IP192.168.10.51)",
      "NAT Process on Firewall:",
      "Attack: 205.174.165.73 -> 205.174.165.80 (IP Valid Firewall) -> 172.16.0.11 -> 192.168.10.51",
      "Reply: 192.168.10.51 -> 172.16.0.1 -> 205.174.165.80 -> 205.174.165.73",
      "Thursday, July 6, 2017",
      "Morning",
      "Web Attack \u2013 Brute Force (9:20 \u2013 10 a.m.)",
      "Web Attack \u2013 XSS (10:15 \u2013 10:35 a.m.)",
      "Web Attack \u2013 Sql Injection (10:40 \u2013 10:42 a.m.)",
      "Attacker: Kali, 205.174.165.73",
      "Victim: WebServer Ubuntu, 205.174.165.68 (Local IP192.168.10.50)",
      "NAT Process on Firewall:",
      "Attack: 205.174.165.73 -> 205.174.165.80 (IP Valid Firewall) -> 172.16.0.10 -> 192.168.10.50",
      "Reply: 192.168.10.50 -> 172.16.0.1 -> 205.174.165.80 -> 205.174.165.73",
      "Afternoon",
      "Infiltration \u2013 Dropbox download",
      "Meta exploit Win Vista (14:19 and 14:20-14:21 p.m.) and (14:33 -14:35)",
      "Attacker: Kali, 205.174.165.73",
      "Victim: Windows Vista, 192.168.10.8",
      "Infiltration \u2013 Cool disk \u2013 MAC (14:53 p.m. \u2013 15:00 p.m.)",
      "Attacker: Kali, 205.174.165.73",
      "Victim: MAC, 192.168.10.25",
      "Infiltration \u2013 Dropbox download",
      "Win Vista (15:04 \u2013 15:45 p.m.)",
      "First Step:",
      "Attacker: Kali, 205.174.165.73",
      "Victim: Windows Vista, 192.168.10.8",
      "Second Step (Portscan + Nmap):",
      "Attacker:Vista, 192.168.10.8",
      "Victim: All other clients",
      "Friday, July 7, 2017",
      "Morning",
      "Botnet ARES (10:02 a.m. \u2013 11:02 a.m.)",
      "Attacker: Kali, 205.174.165.73",
      "Victims: Win 10, 192.168.10.15 + Win 7, 192.168.10.9 + Win 10, 192.168.10.14 + Win 8, 192.168.10.5 + Vista, 192.168.10.8",
      "Afternoon",
      "Port Scan:",
      "Firewall Rule on (13:55 \u2013 13:57, 13:58 \u2013 14:00, 14:01 \u2013 14:04, 14:05 \u2013 14:07, 14:08 - 14:10, 14:11 \u2013 14:13, 14:14 \u2013 14:16, 14:17 \u2013 14:19, 14:20 \u2013 14:21, 14:22 \u2013 14:24, 14:33 \u2013 14:33, 14:35 - 14:35)",
      "Firewall rules off (sS 14:51-14:53, sT 14:54-14:56, sF 14:57-14:59, sX 15:00-15:02, sN 15:03-15:05, sP 15:06-15:07, sV 15:08-15:10, sU 15:11-15:12, sO 15:13-15:15, sA 15:16-15:18, sW 15:19-15:21, sR 15:22-15:24, sL 15:25-15:25, sI 15:26-15:27, b 15:28-15:29)",
      "Attacker: Kali, 205.174.165.73",
      "Victim: Ubuntu16, 205.174.165.68 (Local IP: 192.168.10.50)",
      "NAT Process on Firewall:",
      "Attacker: 205.174.165.73 -> 205.174.165.80 (IP Valid Firewall) -> 172.16.0.1",
      "Afternoon",
      "DDoS LOIT (15:56 \u2013 16:16)",
      "Attackers: Three Win 8.1, 205.174.165.69 - 71",
      "Victim: Ubuntu16, 205.174.165.68 (Local IP: 192.168.10.50)",
      "NAT Process on Firewall:",
      "Attackers: 205.174.165.69, 70, 71 -> 205.174.165.80 (IP Valid Firewall) -> 172.16.0.1",
      "License",
      "The CICIDS2017 dataset consists of labeled network flows, including full packet payloads in pcap format, the corresponding profiles and the labeled flows (GeneratedLabelledFlows.zip) and CSV files for machine and deep learning purpose (MachineLearningCSV.zip) are publicly available for researchers. If you are using our dataset, you should cite our related paper which outlining the details of the dataset and its underlying principles:",
      "Iman Sharafaldin, Arash Habibi Lashkari, and Ali A. Ghorbani, \u201cToward Generating a New Intrusion Detection Dataset and Intrusion Traffic Characterization\u201d, 4th International Conference on Information Systems Security and Privacy (ICISSP), Portugal, January 2018"
    ],
    "paper": null,
    "introduced_date": null,
    "warning": null,
    "modalities": [],
    "tasks": [
      {
        "task": "Network Intrusion Detection",
        "url": "https://paperswithcode.com/task/network-intrusion-detection"
      }
    ],
    "languages": [],
    "variants": [
      "CICIDS2017"
    ],
    "num_papers": 16,
    "data_loaders": []
  },
  {
    "url": "https://paperswithcode.com/dataset/mta-kdd-19",
    "name": "MTA-KDD'19",
    "full_name": "Malware Traffic Analysis Knowledge Dataset 2019",
    "homepage": "https://github.com/IvanLetteri/MTA-KDD-19",
    "description": [
      "Malware Traffic Analysis Knowledge Dataset 2019 (MTA-KDD'19) is an updated and refined dataset specifically tailored to train and evaluate machine learning based malware traffic analysis algorithms. To generate it, that authors started from the largest databases of network traffic captures available online, deriving a dataset with a set of widely-applicable features and then cleaning and preprocessing it to remove noise, handle missing data and keep its size as small as possible. The resulting dataset is not biased by any specific application (although specifically addressed to machine learning algorithms), and the entire process can run automatically to keep it updated.",
      "Source: [Letteri et al.](http://ceur-ws.org/Vol-2597/paper-14.pdf)"
    ],
    "paper": {
      "title": "A Novel Resampling Technique for Imbalanced Dataset Optimization",
      "url": "https://paperswithcode.com/paper/a-novel-resampling-technique-for-imbalanced"
    },
    "introduced_date": "2020-12-30",
    "warning": null,
    "modalities": [],
    "tasks": [],
    "languages": [
      "English"
    ],
    "variants": [
      "MTA-KDD'19"
    ],
    "num_papers": 1,
    "data_loaders": [
      {
        "url": "https://github.com/IvanLetteri/MTA-KDD-19",
        "repo": "https://github.com/IvanLetteri/MTA-KDD-19",
        "frameworks": [
          "none"
        ]
      }
    ]
  },
  {
    "url": "https://paperswithcode.com/dataset/kdd-cup-1999-data-data-set",
    "name": "KDD Cup 1999",
    "full_name": "",
    "homepage": "https://archive.ics.uci.edu/ml/datasets/kdd+cup+1999+data",
    "description": [
      "This is the data set used for The Third International Knowledge Discovery and Data Mining Tools Competition, which was held in conjunction with KDD-99 The Fifth International Conference on Knowledge Discovery and Data Mining. The competition task was to build a network intrusion detector, a predictive model capable of distinguishing between ``bad'' connections, called intrusions or attacks, and ``good'' normal connections. This database contains a standard set of data to be audited, which includes a wide variety of intrusions simulated in a military network environment."
    ],
    "paper": null,
    "introduced_date": "1999-01-01",
    "warning": null,
    "modalities": [],
    "tasks": [
      {
        "task": "Anomaly Detection",
        "url": "https://paperswithcode.com/task/anomaly-detection"
      }
    ],
    "languages": [],
    "variants": [
      "KDD Cup 1999"
    ],
    "num_papers": 5,
    "data_loaders": [
      {
        "url": "https://www.tensorflow.org/datasets/catalog/kddcup99",
        "repo": "https://github.com/tensorflow/datasets",
        "frameworks": [
          "tf",
          "pytorch",
          "jax"
        ]
      }
    ]
  },
  {
    "url": "https://paperswithcode.com/dataset/sidd-network",
    "name": "SIDD-Image",
    "full_name": "Segmented Intrusion Detection Dataset",
    "homepage": "https://www.kaggle.com/datasets/yuweisunut/sidd-segmented-intrusion-detection-dataset",
    "description": [
      "This is the first image-based network intrusion detection dataset. This large-scale dataset included network traffic protocol communication-based images from 15 different observation locations of different countries in Asia. This dataset is used to identify two different types of anomalies from benign network traffic. Each image with a size of 48 \u00d7 48 contains multi-protocol communications within 128 seconds. The SIDD dataset can be to applied to a broad range of tasks such as machine learning-based network intrusion detection, non-iid federated learning, and so forth."
    ],
    "paper": {
      "title": "Adaptive Intrusion Detection in the Networking of Large-Scale LANs with Segmented Federated Learning",
      "url": "https://paperswithcode.com/paper/adaptive-intrusion-detection-in-the"
    },
    "introduced_date": "2020-12-16",
    "warning": null,
    "modalities": [
      "Images"
    ],
    "tasks": [
      {
        "task": "Image Classification",
        "url": "https://paperswithcode.com/task/image-classification"
      },
      {
        "task": "Network Intrusion Detection",
        "url": "https://paperswithcode.com/task/network-intrusion-detection"
      }
    ],
    "languages": [
      "English"
    ],
    "variants": [
      "SIDD-Image"
    ],
    "num_papers": 3,
    "data_loaders": []
  },
  {
    "url": "https://paperswithcode.com/dataset/edge-iiotset",
    "name": "EDGE-IIOTSET",
    "full_name": "A NEW COMPREHENSIVE REALISTIC CYBER SECURITY DATASET OF IOT AND IIOT APPLICATIONS: CENTRALIZED AND FEDERATED LEARNING",
    "homepage": "https://ieee-dataport.org/documents/edge-iiotset-new-comprehensive-realistic-cyber-security-dataset-iot-and-iiot-applications",
    "description": [
      "ABSTRACT",
      "In this project, we propose a new comprehensive realistic cyber security dataset of IoT and IIoT applications, called Edge-IIoTset, which can be used by machine learning-based intrusion detection systems in two different modes, namely, centralized and federated learning. Specifically, the proposed testbed is organized into seven layers, including, Cloud Computing Layer, Network Functions Virtualization Layer, Blockchain Network Layer, Fog Computing Layer, Software-Defined Networking Layer, Edge Computing Layer, and IoT and IIoT Perception Layer. In each layer, we propose new emerging technologies that satisfy the key requirements of IoT and IIoT applications, such as, ThingsBoard IoT platform, OPNFV platform, Hyperledger Sawtooth, Digital twin, ONOS SDN controller, Mosquitto MQTT brokers, Modbus TCP/IP, ...etc. The IoT data are generated from various IoT devices (more than 10 types) such as Low-cost digital sensors for sensing temperature and humidity, Ultrasonic sensor, Water level detection sensor, pH Sensor Meter, Soil Moisture sensor, Heart Rate Sensor, Flame Sensor, ...etc.). However, we identify and analyze fourteen attacks related to IoT and IIoT connectivity protocols, which are categorized into five threats, including, DoS/DDoS attacks, Information gathering, Man in the middle attacks, Injection attacks, and Malware attacks. In addition, we extract features obtained from different sources, including alerts, system resources, logs, network traffic, and propose new 61 features with high correlations from 1176 found features. After processing and analyzing the proposed realistic cyber security dataset, we provide a primary exploratory data analysis and evaluate the performance of machine learning approaches (i.e., traditional machine learning as well as deep learning) in both centralized and federated learning modes.",
      "Instructions:",
      "Great news! The Edge-IIoT dataset has been featured as a \"Document in the top 1% of Web of Science.\" This indicates that it is ranked within the top 1% of all publications indexed by the Web of Science (WoS) in terms of citations and impact.",
      "Please kindly visit kaggle link for the updates: https://www.kaggle.com/datasets/mohamedamineferrag/edgeiiotset-cyber-sec...",
      "Free use of the Edge-IIoTset dataset for academic research purposes is hereby granted in perpetuity. Use for commercial purposes is allowable after asking the leader author, Dr Mohamed Amine Ferrag, who has asserted his right under the Copyright.",
      "The details of the Edge-IIoT dataset were published in following the paper. For the academic/public use of these datasets, the authors have to cities the following paper:",
      "Mohamed Amine Ferrag, Othmane Friha, Djallel Hamouda, Leandros Maglaras, Helge Janicke, \"Edge-IIoTset: A New Comprehensive Realistic Cyber Security Dataset of IoT and IIoT Applications for Centralized and Federated Learning\", IEEE Access, April 2022 (IF: 3.37), DOI: 10.1109/ACCESS.2022.3165809",
      "Link to paper : https://ieeexplore.ieee.org/document/9751703",
      "********************************************",
      "The directories of the Edge-IIoTset dataset include the following:",
      "\u2022File 1 (Normal traffic)",
      "-File 1.1 (Distance): This file includes two documents, namely, Distance.csv and Distance.pcap. The IoT sensor (Ultrasonic sensor) is used to capture the IoT data.",
      "-File 1.2 (Flame_Sensor): This file includes two documents, namely, Flame_Sensor.csv and Flame_Sensor.pcap. The IoT sensor (Flame Sensor) is used to capture the IoT data.",
      "-File 1.3 (Heart_Rate): This file includes two documents, namely, Flame_Sensor.csv and Flame_Sensor.pcap. The IoT sensor (Flame Sensor) is used to capture the IoT data.",
      "-File 1.4 (IR_Receiver): This file includes two documents, namely, IR_Receiver.csv and IR_Receiver.pcap. The IoT sensor (IR (Infrared) Receiver Sensor) is used to capture the IoT data.",
      "-File 1.5 (Modbus): This file includes two documents, namely, Modbus.csv and Modbus.pcap. The IoT sensor (Modbus Sensor) is used to capture the IoT data.",
      "-File 1.6 (phValue): This file includes two documents, namely, phValue.csv and phValue.pcap. The IoT sensor (pH-sensor PH-4502C) is used to capture the IoT data.",
      "-File 1.7 (Soil_Moisture): This file includes two documents, namely, Soil_Moisture.csv and Soil_Moisture.pcap. The IoT sensor (Soil Moisture Sensor v1.2) is used to capture the IoT data.",
      "-File 1.8 (Sound_Sensor): This file includes two documents, namely, Sound_Sensor.csv and Sound_Sensor.pcap. The IoT sensor (LM393 Sound Detection Sensor) is used to capture the IoT data.",
      "-File 1.9 (Temperature_and_Humidity): This file includes two documents, namely, Temperature_and_Humidity.csv and Temperature_and_Humidity.pcap. The IoT sensor (DHT11 Sensor) is used to capture the IoT data.",
      "-File 1.10 (Water_Level): This file includes two documents, namely, Water_Level.csv and Water_Level.pcap. The IoT sensor (Water sensor) is used to capture the IoT data.",
      "\u2022File 2 (Attack traffic):",
      "-File 2.1 (Attack traffic (CSV files)): This file includes 13 documents, namely, Backdoor_attack.csv, DDoS_HTTP_Flood_attack.csv, DDoS_ICMP_Flood_attack.csv, DDoS_TCP_SYN_Flood_attack.csv, DDoS_UDP_Flood_attack.csv, MITM_attack.csv, OS_Fingerprinting_attack.csv, Password_attack.csv, Port_Scanning_attack.csv, Ransomware_attack.csv, SQL_injection_attack.csv, Uploading_attack.csv, Vulnerability_scanner_attack.csv, XSS_attack.csv. Each document is specific for each attack.",
      "-File 2.2 (Attack traffic (PCAP files)): This file includes 13 documents, namely, Backdoor_attack.pcap, DDoS_HTTP_Flood_attack.pcap, DDoS_ICMP_Flood_attack.pcap, DDoS_TCP_SYN_Flood_attack.pcap, DDoS_UDP_Flood_attack.pcap, MITM_attack.pcap, OS_Fingerprinting_attack.pcap, Password_attack.pcap, Port_Scanning_attack.pcap, Ransomware_attack.pcap, SQL_injection_attack.pcap, Uploading_attack.pcap, Vulnerability_scanner_attack.pcap, XSS_attack.pcap. Each document is specific for each attack.",
      "\u2022File 3 (Selected dataset for ML and DL):",
      "-File 3.1 (DNN-EdgeIIoT-dataset): This file contains a selected dataset for the use of evaluating deep learning-based intrusion detection systems.",
      "-File 3.2 (ML-EdgeIIoT-dataset): This file contains a selected dataset for the use of evaluating traditional machine learning-based intrusion detection systems.",
      "********************************************",
      "Step 1: Downloading The Edge-IIoTset dataset From the Kaggle platform",
      "from google.colab import files",
      "!pip install -q kaggle",
      "files.upload()",
      "!mkdir ~/.kaggle",
      "!cp kaggle.json ~/.kaggle/",
      "!chmod 600 ~/.kaggle/kaggle.json",
      "!kaggle datasets download -d mohamedamineferrag/edgeiiotset-cyber-security-dataset-of-iot-iiot -f \"Edge-IIoTset dataset/Selected dataset for ML and DL/DNN-EdgeIIoT-dataset.csv\"",
      "!unzip DNN-EdgeIIoT-dataset.csv.zip",
      "!rm DNN-EdgeIIoT-dataset.csv.zip",
      "Step 2: Reading the Datasets' CSV file to a Pandas DataFrame:",
      "import pandas as pd",
      "import numpy as np",
      "df = pd.read_csv('DNN-EdgeIIoT-dataset.csv', low_memory=False)",
      "Step 3 : Exploring some of the DataFrame's contents:",
      "df.head(5)",
      "print(df['Attack_type'].value_counts())",
      "Step 4: Dropping data (Columns, duplicated rows, NAN, Null..):",
      "from sklearn.utils import shuffle",
      "drop_columns = [\"frame.time\", \"ip.src_host\", \"ip.dst_host\", \"arp.src.proto_ipv4\",\"arp.dst.proto_ipv4\",",
      "\"http.file_data\",\"http.request.full_uri\",\"icmp.transmit_timestamp\",",
      "\"http.request.uri.query\", \"tcp.options\",\"tcp.payload\",\"tcp.srcport\",",
      "\"tcp.dstport\", \"udp.port\", \"mqtt.msg\"]",
      "df.drop(drop_columns, axis=1, inplace=True)",
      "df.dropna(axis=0, how='any', inplace=True)",
      "df.drop_duplicates(subset=None, keep=\"first\", inplace=True)",
      "df = shuffle(df)",
      "df.isna().sum()",
      "print(df['Attack_type'].value_counts())",
      "Step 5: Categorical data encoding (Dummy Encoding):",
      "import numpy as np",
      "from sklearn.model_selection import train_test_split",
      "from sklearn.preprocessing import StandardScaler",
      "from sklearn import preprocessing",
      "def encode_text_dummy(df, name):",
      "dummies = pd.get_dummies(df[name])",
      "for x in dummies.columns:",
      "dummy_name = f\"{name}-{x}\"",
      "df[dummy_name] = dummies[x]",
      "df.drop(name, axis=1, inplace=True)",
      "encode_text_dummy(df,'http.request.method')",
      "encode_text_dummy(df,'http.referer')",
      "encode_text_dummy(df,\"http.request.version\")",
      "encode_text_dummy(df,\"dns.qry.name.len\")",
      "encode_text_dummy(df,\"mqtt.conack.flags\")",
      "encode_text_dummy(df,\"mqtt.protoname\")",
      "encode_text_dummy(df,\"mqtt.topic\")",
      "Step 6: Creation of the preprocessed dataset",
      "df.to_csv('preprocessed_DNN.csv', encoding='utf-8')",
      "********************************************",
      "For more information about the dataset, please contact the lead author of this project, Dr Mohamed Amine Ferrag, on his email: mohamed.amine.ferrag@gmail.com",
      "More information about Dr. Mohamed Amine Ferrag is available at:",
      "https://www.linkedin.com/in/Mohamed-Amine-Ferrag",
      "https://dblp.uni-trier.de/pid/142/9937.html",
      "https://www.researchgate.net/profile/Mohamed_Amine_Ferrag",
      "https://scholar.google.fr/citations?user=IkPeqxMAAAAJ&hl=fr&oi=ao",
      "https://www.scopus.com/authid/detail.uri?authorId=56115001200",
      "https://publons.com/researcher/1322865/mohamed-amine-ferrag/",
      "https://orcid.org/0000-0002-0632-3172",
      "Last Updated: 27 Mar. 2023"
    ],
    "paper": null,
    "introduced_date": null,
    "warning": null,
    "modalities": [],
    "tasks": [
      {
        "task": "Intrusion Detection",
        "url": "https://paperswithcode.com/task/intrusion-detection"
      },
      {
        "task": "Network Intrusion Detection",
        "url": "https://paperswithcode.com/task/network-intrusion-detection"
      }
    ],
    "languages": [
      "English"
    ],
    "variants": [
      "EDGE-IIOTSET"
    ],
    "num_papers": 3,
    "data_loaders": []
  },
  {
    "url": "https://paperswithcode.com/dataset/ollabench-v-0-2",
    "name": "OllaBench v.0.2",
    "full_name": "OllaBench for Interdependent Cybersecurity v.0.2",
    "homepage": "https://github.com/Cybonto/OllaBench",
    "description": [
      "Large Language Models (LLMs) have the potential to enhance Agent-Based Modeling by better representing complex interdependent cybersecurity systems, improving cybersecurity threat modeling and risk management. Evaluating LLMs in this context is crucial for legal compliance and effective application development. Existing LLM evaluation frameworks often overlook the human factor and cognitive computing capabilities essential for interdependent cybersecurity. To address this gap, I propose OllaBench, a novel evaluation framework that assesses LLMs' accuracy, wastefulness, and consistency in answering scenario-based information security compliance and non-compliance questions."
    ],
    "paper": {
      "title": "Ollabench: Evaluating LLMs' Reasoning for Human-centric Interdependent Cybersecurity",
      "url": "https://paperswithcode.com/paper/ollabench-evaluating-llms-reasoning-for-human"
    },
    "introduced_date": "2024-06-11",
    "warning": null,
    "modalities": [
      "Texts"
    ],
    "tasks": [
      {
        "task": "Multiple-choice",
        "url": "https://paperswithcode.com/task/multiple-choice"
      },
      {
        "task": "Moral Scenarios",
        "url": "https://paperswithcode.com/task/moral-scenarios"
      },
      {
        "task": "Computer Security",
        "url": "https://paperswithcode.com/task/computer-security"
      }
    ],
    "languages": [
      "English"
    ],
    "variants": [
      "OllaBench v.0.2"
    ],
    "num_papers": 1,
    "data_loaders": []
  },
  {
    "url": "https://paperswithcode.com/dataset/arinc-429-voltage-data",
    "name": "ARINC 429 Voltage Data",
    "full_name": "",
    "homepage": "https://testscience.org/arinc/",
    "description": [
      "This page contains ARINC 429 message data recorded from the hardware-in-a-loop simulator. These messages were recorded using a SIGLENT SDS2204X Plus oscilloscope sampling at 20 MHz. The intent of this data is to enable cybersecurity research and development for ARINC 429 by providing detailed message data from multiple hardware sources.",
      "The dataset consists of three csv files of ARINC 429 messages along with a data dictionary markdown file. The zip file is 550MB and each csv file is approximately 1.5GB. The csv filenames indicate which transmitter the messages were being sent from, with the EGPWS representing a \u201cvalid\u201d transmitter while the RTX and AltaDT both represent adversarial transmitters."
    ],
    "paper": {
      "title": "ARINC 429 Cyber-vulnerabilities and Voltage Data in a Hardware-in-the-Loop Simulator",
      "url": "https://paperswithcode.com/paper/arinc-429-cyber-vulnerabilities-and-voltage"
    },
    "introduced_date": "2024-08-29",
    "warning": null,
    "modalities": [
      "Time series"
    ],
    "tasks": [
      {
        "task": "Intrusion Detection",
        "url": "https://paperswithcode.com/task/intrusion-detection"
      }
    ],
    "languages": [
      "English"
    ],
    "variants": [
      "ARINC 429 Voltage Data"
    ],
    "num_papers": 1,
    "data_loaders": []
  },
  {
    "url": "https://paperswithcode.com/dataset/cic-iomt-dataset-2024",
    "name": "CIC IoMT dataset 2024",
    "full_name": "",
    "homepage": "https://www.unb.ca/cic/datasets/iomt-dataset-2024.html",
    "description": [
      "The **CICIoMT2024 dataset** is a comprehensive dataset designed for cybersecurity research focused on the Internet of Medical Things (IoMT). Developed by the Canadian Institute for Cybersecurity, it simulates realistic IoMT network traffic, representing the diverse and evolving threats faced by connected healthcare devices. The dataset comprises network traffic data from various IoMT devices, with labeled instances for 18 distinct types of cyberattacks, alongside benign traffic data.",
      "Each cyberattack type is meticulously crafted to reflect common and advanced threats, such as Distributed Denial of Service (DDoS), ransomware, man-in-the-middle attacks, and malware injections. With a balanced mix of attacks and benign instances, CICIoMT2024 enables robust training and testing for various cybersecurity models.",
      "The CICIoMT2024 dataset\u2019s detailed packet-level information and multi-class labels make it ideal for developing and evaluating machine learning and deep learning algorithms. Its design emphasizes real-world application, making it a valuable resource for researchers aiming to enhance IoMT security, protect patient data, and ensure the resilience of medical networks against cyber threats."
    ],
    "paper": null,
    "introduced_date": null,
    "warning": null,
    "modalities": [],
    "tasks": [],
    "languages": [],
    "variants": [
      "CIC IoMT dataset 2024"
    ],
    "num_papers": 0,
    "data_loaders": []
  },
  {
    "url": "https://paperswithcode.com/dataset/cybench",
    "name": "Cybench",
    "full_name": "",
    "homepage": "https://cybench.github.io/",
    "description": [
      "Language Model (LM) agents for cybersecurity that are capable of autonomously identifying vulnerabilities and executing exploits have potential to cause real-world impact. Policymakers, model providers, and researchers in the AI and cybersecurity communities are interested in quantifying the capabilities of such agents to help mitigate cyberrisk and investigate opportunities for penetration testing. Toward that end, we introduce Cybench, a framework for specifying cybersecurity tasks and evaluating agents on those tasks. We include 40 professional-level Capture the Flag (CTF) tasks from 4 distinct CTF competitions, chosen to be recent, meaningful, and spanning a wide range of difficulties. Each task includes its own description, starter files, and is initialized in an environment where an agent can execute commands and observe outputs. Since many tasks are beyond the capabilities of existing LM agents, we introduce subtasks for each task, which break down a task into intermediary steps for a more detailed evaluation. To evaluate agent capabilities, we construct a cybersecurity agent and evaluate 8 models: GPT-4o, OpenAI o1-preview, Claude 3 Opus, Claude 3.5 Sonnet, Mixtral 8x22b Instruct, Gemini 1.5 Pro, Llama 3 70B Chat, and Llama 3.1 405B Instruct. For the top performing models (GPT-4o and Claude 3.5 Sonnet), we further investigate performance across 4 agent scaffolds (structed bash, action-only, pseudoterminal, and web search). Without subtask guidance, agents leveraging Claude 3.5 Sonnet, GPT-4o, OpenAI o1-preview, and Claude 3 Opus successfully solved complete tasks that took human teams up to 11 minutes to solve. In comparison, the most difficult task took human teams 24 hours and 54 minutes to solve. All code and data are publicly available at https://cybench.github.io/."
    ],
    "paper": {
      "title": "Cybench: A Framework for Evaluating Cybersecurity Capabilities and Risks of Language Models",
      "url": "https://paperswithcode.com/paper/cybench-a-framework-for-evaluating"
    },
    "introduced_date": "2024-08-15",
    "warning": null,
    "modalities": [],
    "tasks": [
      {
        "task": "",
        "url": "https://paperswithcode.com/task/task"
      }
    ],
    "languages": [],
    "variants": [
      "Cybench"
    ],
    "num_papers": 5,
    "data_loaders": []
  },
  {
    "url": "https://paperswithcode.com/dataset/cybersecurity-threat-detection",
    "name": "Cybersecurity Threat Detection",
    "full_name": "",
    "homepage": "https://globaltechnosol.com/case_studies/cybersecurity-threat-detection/",
    "description": [
      "Problem Statement",
      "<a href=\"https://globaltechnosol.com/case_studies/Cybersecurity-Threat-Detection/\" target=\"_blank\">\ud83d\udc49 Download the case studies here</a>",
      "Organizations face an increasing number of sophisticated cybersecurity threats, including malware, phishing attacks, and unauthorized access. A financial institution experienced frequent attempts to breach its network, risking sensitive data and regulatory compliance. Traditional security measures were reactive and failed to detect threats in real time. The institution sought a proactive AI-driven solution to identify and prevent cybersecurity threats effectively.",
      "Challenge",
      "Developing an advanced threat detection system required addressing several challenges:",
      "Processing and analyzing large volumes of network traffic and user activity data in real time.",
      "Identifying new and evolving threats, such as zero-day vulnerabilities, with high accuracy.",
      "Minimizing false positives to ensure security teams could focus on genuine threats.",
      "Solution Provided",
      "An AI-powered threat detection system was developed using machine learning algorithms and advanced analytics. The solution was designed to:",
      "Continuously monitor network activity and user behavior to identify suspicious patterns.",
      "Detect and neutralize cybersecurity threats in real time, including malware and phishing attempts.",
      "Provide actionable insights to security teams for faster and more effective threat response.",
      "Development Steps",
      "Data Collection",
      "Collected network traffic logs, endpoint activity, and historical threat data to train machine learning models.",
      "Preprocessing",
      "Cleaned and standardized data, ensuring compatibility across diverse sources, and filtered out noise for accurate analysis.",
      "Model Development",
      "Developed machine learning algorithms for anomaly detection, behavioral analysis, and threat classification. Trained models on labeled datasets to recognize known threats and identify emerging attack patterns.",
      "Validation",
      "Tested the system against simulated and real-world threat scenarios to evaluate detection accuracy, response times, and reliability.",
      "Deployment",
      "Integrated the threat detection system into the institution\u2019s existing cybersecurity infrastructure, including firewalls, SIEM (Security Information and Event Management) tools, and endpoint protection",
      "Continuous Monitoring & Improvement",
      "Established a feedback loop to refine models using new threat data and adapt to evolving attack strategies.",
      "Results",
      "Enhanced Security Posture",
      "The system improved the institution\u2019s ability to detect and prevent cybersecurity threats proactively, strengthening its overall security framework.",
      "Reduced Incidence of Cyber Attacks",
      "Real-time detection and response significantly reduced the frequency and impact of successful cyber attacks.",
      "Improved Threat Response Times",
      "Automated threat identification and prioritization enabled security teams to respond faster and more effectively to potential breaches.",
      "Minimized False Positives",
      "Advanced algorithms reduced false alarms, allowing security teams to focus on genuine threats and improve efficiency.",
      "Scalable and Adaptive Solution",
      "The system adapted to new threats and scaled effortlessly to protect growing organizational networks and data."
    ],
    "paper": null,
    "introduced_date": null,
    "warning": null,
    "modalities": [],
    "tasks": [],
    "languages": [
      "English"
    ],
    "variants": [
      "Cybersecurity Threat Detection"
    ],
    "num_papers": 0,
    "data_loaders": []
  },
  {
  "url": "https://paperswithcode.com/dataset/cic-ddos2019",
  "name": "CIC-DDoS2019",
  "full_name": "CIC-DDoS2019",
  "homepage": "https://www.kaggle.com/datasets/dhoogla/cicddos2019",
  "description": [
    "his is an academic intrusion detection dataset.",
    "All the credit goes to the original authors: Dr. Iman Sharafaldin, Dr. Saqib Hakak, Dr. Arash Habibi Lashkari Dr. Ali Ghorbani. Please cite their original paper.",
    "The dataset offers an extended set of Distributed Denial of Service attacks, most of which employ some form of amplification through reflection. The dataset shares its feature set with the other CIC NIDS datasets, IDS2017, IDS2018 and DoS2017"
  ],
  "paper": {
    "title": "LUCID: A Practical, Lightweight Deep Learning Solution for DDoS Attack Detection",
    "url": "https://paperswithcode.com/paper/lucid-a-practical-lightweight-deep-learning"
  },
  "introduced_date": "2020-02-12",
  "warning": null,
  "modalities": [],
  "tasks": [],
  "languages": [],
  "variants": [
    "CIC-DDoS2019"
  ],
  "num_papers": 8,
  "data_loaders": []
},
{
    "url": "https://paperswithcode.com/dataset/cic-iot-dataset-2022",
    "name": "CIC IoT Dataset 2022",
    "full_name": "",
    "homepage": "https://www.unb.ca/cic/datasets/iotdataset-2022.html",
    "description": [
      "# CIC IoT Dataset 2022",
      "This project aims to generate a state-of-the-art dataset for profiling, behavioural analysis, and vulnerability testing of different IoT devices with different protocols such as IEEE 802.11, Zigbee-based and Z-Wave. The following illustrates the main objectives of the CIC-IoT dataset project:",
      "- Configure various IoT devices and analyze the behaviour exhibited.",
      "- Conduct manual and semi-automated experiments of various categories.",
      "- Further analyze the network traffic when the devices are idle for three minutes and when powered on for the first two minutes.",
      "- Generating different scenarios and analyzing the devices' behaviour in different situations.",
      "- Conducting and capturing the network terrific of devices undercurrent and important attacks in IoT environment.",
      "Current CIC IoT dataset project and activities around it can be summarized in the following steps:",
      "### Network configuration",
      "Our lab network configuration was configured with a 64-bit Window machine with two network interface cards - one is connected to the network gateway, and the other is connected to an unmanaged network switch. Simultaneously, [Wireshark](https://www.wireshark.org/), the open-source network protocol analyzer, listens to both interfaces, captures and saves the output packet captured (pcap) files. Hence, IoT devices that require an Ethernet connection are connected to this switch. Additionally, a smart automation hub, Vera Plus is also connected to the unmanaged switch, which creates our wireless IoT environment to serve IoT devices compatible with Wi-Fi, ZigBee, Z-Wave and Bluetooth.",
      "![](https://www.unb.ca/cic/_assets/images/iot-dataset.jpg)",
      "### Dataset",
      "For collecting the data, we captured the network traffic of the IoT devices coming through the gateway using Wireshark and dumpcap in six different types of experiments. The former was used for manual experiments, while the latter was used for semi-automated ones. All the experiments can be organized as follows:",
      "1. **Power:**  In this experiment, we powered on all the devices in our lab individually and started a network traffic capture in isolation.",
      "1. **Idle:**  In this experiment, we captured the whole network traffic from late in the evening to early in the morning, which we call idle time. In this period, the whole lab was completely evacuated and there were no human interactions involved.",
      "1. **Interactions:**  In this experiment, all possible functionality on IoT devices has been extracted and the corresponding network activity and transmitted packets for each functionality/activity have been captured.",
      "1. **Scenarios:**  In these experiments, we conducted six different types of scenario experiments using a combination of devices as simulations of the network activity inside a smart home. These experiments were done to see how devices behave while interacting with each other simultaneously.",
      "1. **Active:**  In addition to the idle time, the whole network communications were also captured throughout the day. All fellow researchers during this period were allowed to enter the lab whenever they wanted. They might interact with devices and generate network traffic either passively or actively.",
      "1. **Attacks:**  In this experiment, we performed two different attacks, Flood and RTSP- Brute Force, on some of our devices and captured their attack network traffic.",
      "### Case study \u2013 device identification",
      "After generating the dataset, we performed a case study on the idea of transferability \u2013 training datasets in our lab and transferring the trained model to another lab for testing. We conducted 20 different experiments based on the number of sampled devices from the United States lab.",
      "Forty-eight features were extracted from both the training dataset from our lab and the testing dataset from the other lab. Three classes of device types were used in this experiment: Audio, Camera and Home Automation. However, no labels were required for the test dataset since that was what was to be predicted but the training dataset required labels.",
      "After training, the model is transferred to the other lab for testing on each device to predict the class of the device in question. For example, if Amazon Echo Dot is tested on the trained model, the classifier should be able to predict this device as belonging to device type Audio. How this works is by counting the prediction of the classifier based on the features for each device type. The device type with the highest count is predicted as the class for the device in question.",
      "### Dataset directory",
      "The main dataset directory (CIC IoT Dataset) contains six subdirectories related to each experiment, namely:",
      "1. **Power:**  In this directory, you will find the power experiment packet captures for each device, categorized by different device classes.",
      "1. **Idle:**  In this directory, you will find idle experiment packet captures for 30 days, named and sorted by date.",
      "1. **Interactions:**  In this directory, you will find the interactions experiments packet captures for each device, categorized by different device classes. Each interaction includes three packet captures.",
      "1. **Scenarios:**  In this directory, you will find six sub-directories, each of which is related to one scenario. Each scenario includes three packet captures.",
      "1. **Active:**  In this directory, you will find active experiment packet captures for 30 days, named and sorted by date.",
      "1. **Attacks:**  In this directory, you will find two sub-directories, Flood and RTSP BruteForce, each for a specific attack performed on a few devices. The latter was performed using two different tools, Hydra and Nmap. Each attack includes three packet captures per device.",
      "### Contributing",
      "The project is not currently in development, but any contribution is welcome. Please contact one of the authors of the paper.",
      "### Acknowledgments",
      "The authors would like to thank the [Canadian Institute for Cybersecurity](https://www.unb.ca/cic/about/index.html) for its financial and educational support.",
      "### Citation",
      "Sajjad Dadkhah, Hassan Mahdikhani, Priscilla Kyei Danso, Alireza Zohourian, Kevin Anh Truong, Ali A. Ghorbani, \"[_Towards the development of a realistic multidimensional IoT profiling dataset_](https://ieeexplore.ieee.org/document/9851966)\", Submitted to: The 19th Annual International Conference on Privacy, Security & Trust (PST2022) August 22-24, 2022, Fredericton, Canada."
    ],
    "paper": null,
    "introduced_date": "2022-03-22",
    "warning": null,
    "modalities": [],
    "tasks": [
      {
        "task": "Network Intrusion Detection",
        "url": "https://paperswithcode.com/task/network-intrusion-detection"
      }
    ],
    "languages": [
      "English"
    ],
    "variants": [
      "CIC IoT Dataset 2022"
    ],
    "num_papers": 2,
    "data_loaders": []
  }
]
