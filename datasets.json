[
  {
    "url": "https://paperswithcode.com/dataset/unsw-nb15",
    "name": "UNSW-NB15",
    "full_name": "UNSQ-NB15",
    "homepage": "https://www.unsw.adfa.edu.au/unsw-canberra-cyber/cybersecurity/ADFA-NB15-Datasets/",
    "description": [
      "**UNSW-NB15** is a network intrusion dataset. It contains nine different attacks, includes DoS, worms, Backdoors, and Fuzzers. The dataset contains raw network packets. The number of records in the training set is 175,341 records and the testing set is 82,332 records from the different types, attack and normal.",
      "Source: [Evaluation of Adversarial Training on Different Types of Neural Networks in Deep Learning-based IDSs](https://arxiv.org/abs/2007.04472)",
      "Image Source: [https://www.unsw.adfa.edu.au/unsw-canberra-cyber/cybersecurity/ADFA-NB15-Datasets/](https://www.unsw.adfa.edu.au/unsw-canberra-cyber/cybersecurity/ADFA-NB15-Datasets/)",
      "Paper: [UNSW-NB15: a comprehensive data set for network intrusion detection systems](https://doi.org/10.1109/MilCIS.2015.7348942)"
    ],
    "paper": {
      "title": "UNSW-NB15: a comprehensive data set for network intrusion detection systems (UNSW-NB15 network data set)",
      "url": "https://doi.org/10.1109/MilCIS.2015.7348942"
    },
    "introduced_date": "2015-11-01",
    "warning": null,
    "modalities": [
      "Tabular"
    ],
    "tasks": [
      {
        "task": "Intrusion Detection",
        "url": "https://paperswithcode.com/task/intrusion-detection"
      },
      {
        "task": "Synthetic Data Generation",
        "url": "https://paperswithcode.com/task/synthetic-data-generation"
      },
      {
        "task": "Network Intrusion Detection",
        "url": "https://paperswithcode.com/task/network-intrusion-detection"
      }
    ],
    "languages": [
      "Russian"
    ],
    "variants": [
      "UNSW-NB15"
    ],
    "num_papers": 147,
    "data_loaders": [
      {
        "url": "https://www.kaggle.com/datasets/dhoogla/unswnb15",
        "repo": "https://github.com/Kaggle/kaggle-api",
        "frameworks": []
      }
    ]
  },
  {
    "url": "https://paperswithcode.com/dataset/cry-wolf",
    "name": "Cry Wolf",
    "full_name": "",
    "homepage": "https://uncw-hfcs.github.io/ids-simulator-analysis/",
    "description": [
      "**Cry Wolf** is a dataset for cyber security analysis tasks. It is an open-access dataset of 73 true and false Intrusion Detection System (IDS) alarms derived from real-world examples of \"impossible travel\" scenarios."
    ],
    "paper": {
      "title": "Cry Wolf: Toward an Experimentation Platform and Dataset for Human Factors in Cyber Security Analysis",
      "url": "https://paperswithcode.com/paper/cry-wolf-toward-an-experimentation-platform"
    },
    "introduced_date": "2020-02-24",
    "warning": null,
    "modalities": [],
    "tasks": [],
    "languages": [],
    "variants": [
      "Cry Wolf"
    ],
    "num_papers": 1,
    "data_loaders": []
  },
  {
    "url": "https://paperswithcode.com/dataset/ton-iot",
    "name": "ToN_IoT",
    "full_name": "",
    "homepage": "https://ieee-dataport.org/documents/toniot-datasets",
    "description": [
      "The **TON_IoT** datasets are new generations of Internet of Things (IoT) and Industrial IoT (IIoT) datasets for evaluating the fidelity and efficiency of different cybersecurity applications based on Artificial Intelligence (AI). The datasets have been called \u2018ToN_IoT\u2019 as they include heterogeneous data sources collected from Telemetry datasets of IoT and IIoT sensors, Operating systems datasets of Windows 7 and 10 as well as Ubuntu 14 and 18 TLS and Network traffic datasets. The datasets were collected from a realistic and large-scale network designed at the IoT Lab of the UNSW Canberra Cyber, the School of Engineering and Information technology (SEIT), UNSW Canberra @ the Australian Defence Force Academy (ADFA).",
      "The datasets were gathered in a parallel processing to collect several normal and cyber-attack events from IoT networks. A new testbed was developed at the IoT lab to connect many virtual machine, physical systems, hacking platforms, cloud and fog platforms, IoT and IIoT sensors to mimic the complexity and scalability of industrial IoT and Industry 4.0 networks.",
      "Different hacking techniques, such as DoS, DDoS and ransomware against, were launched against web applications, IoT gateways and computer systems across the IIoT network."
    ],
    "paper": {
      "title": "Federated TON_IoT Windows Datasets for Evaluating AI-based Security Applications",
      "url": "https://paperswithcode.com/paper/federated-ton-iot-windows-datasets-for"
    },
    "introduced_date": "2020-10-04",
    "warning": null,
    "modalities": [],
    "tasks": [
      {
        "task": "Speech Synthesis - Gujarati",
        "url": "https://paperswithcode.com/task/speech-synthesis-gujarati"
      }
    ],
    "languages": [],
    "variants": [
      "ToN_IoT"
    ],
    "num_papers": 7,
    "data_loaders": []
  },
  {
    "url": "https://paperswithcode.com/dataset/analytic-provenance",
    "name": "Analytic Provenance",
    "full_name": "",
    "homepage": "https://research.arch.tamu.edu/analytic-provenance/datasets/",
    "description": [
      "**Analytic provenance** is a data repository that can be used to study human analysis activity, thought processes, and software interaction with visual analysis tools during exploratory data analysis. It was collected during a series of user studies involving exploratory data analysis scenario with textual and cyber security data. Interactions logs, think-alouds, videos and all coded data in this study are available online for research purposes.",
      "Analysis sessions are segmented in multiple sub-task steps based on user think-alouds, video and audios captured during the studies. These analytic provenance datasets can be used for research involving tools and techniques for analyzing interaction logs and analysis history."
    ],
    "paper": {
      "title": "Analytic Provenance Datasets: A Data Repository of Human Analysis Activity and Interaction Logs",
      "url": "https://paperswithcode.com/paper/analytic-provenance-datasets-a-data"
    },
    "introduced_date": "2018-01-16",
    "warning": null,
    "modalities": [],
    "tasks": [],
    "languages": [],
    "variants": [
      "Analytic Provenance"
    ],
    "num_papers": 1,
    "data_loaders": []
  },
  {
    "url": "https://paperswithcode.com/dataset/ctfw",
    "name": "CTFW",
    "full_name": "",
    "homepage": "https://github.com/kuntalkumarpal/FlowGraph",
    "description": [
      "**CTFW** is a large annotated procedural text dataset in the cybersecurity domain (3154 documents). It is used to generate flow graphs from procedural texts."
    ],
    "paper": {
      "title": "Constructing Flow Graphs from Procedural Cybersecurity Texts",
      "url": "https://paperswithcode.com/paper/constructing-flow-graphs-from-procedural"
    },
    "introduced_date": "2021-05-29",
    "warning": null,
    "modalities": [
      "Texts",
      "Graphs"
    ],
    "tasks": [],
    "languages": [
      "English"
    ],
    "variants": [
      "CTFW"
    ],
    "num_papers": 1,
    "data_loaders": []
  },
  {
    "url": "https://paperswithcode.com/dataset/casie",
    "name": "CASIE",
    "full_name": "",
    "homepage": "https://github.com/Ebiquity/CASIE",
    "description": [
      "### Annotation corpus of cybersecurity event in news articles",
      "The corpus contains 1000 annotation and source files. Our cybersecurity focused on five event types: Databreach, Phishing, Ransom, Discover, and Patch.",
      "More details of the annotation and CASIE's system are in the papers. If you use our data, please cite one of the following papers.",
      "Taneeya Satyapanich, Francis Ferraro, and Tim Finin, \"CASIE: Extracting Cybersecurity Event Information from Text\", InProceedings, Proceeding of the 34th AAAI Conference on Artificial Intelligence, February 2020.",
      "Taneeya Satyapanich, Tim Finin, and Francis Ferraro, \"Extracting Rich Semantic Information about Cybersecurity Events\", InProceedings, Second Workshop on Big Data for CyberSecurity, held in conjunction with the IEEE Int. Conf. on Big Data, December 2019.",
      "Any problems found, please contact taneeya1@umbc.edu."
    ],
    "paper": null,
    "introduced_date": null,
    "warning": null,
    "modalities": [],
    "tasks": [],
    "languages": [],
    "variants": [
      "CASIE"
    ],
    "num_papers": 1,
    "data_loaders": []
  },
  {
    "url": "https://paperswithcode.com/dataset/aiseckg",
    "name": "AISECKG",
    "full_name": "AISecKG: Knowledge Graph Dataset for Cybersecurity Education",
    "homepage": "https://github.com/garima0106/AISecKG-cybersecurity-dataset",
    "description": [
      "Cybersecurity education is exceptionally challenging as it involves learning the complex attacks; tools and developing critical problem-solving skills to defend the systems. For a student or novice researcher in the cybersecurity domain, there is a need to design an adaptive learning strategy that can break complex tasks and concepts into simple representations. An AI-enabled automated cybersecurity education system can improve cognitive engagement and active learning. Knowledge graphs (KG) provide a visual representation in a graph that can reason and interpret from the underlying data, making them suitable for use in education and interactive learning. However, there are no publicly available datasets for the cybersecurity education domain to build such systems. The data is present as unstructured educational course material, Wiki pages, capture the flag (CTF) writeups, etc. Creating knowledge graphs from unstructured text is challenging without an ontology or annotated dataset. However, data annotation for cybersecurity needs domain experts. To address these gaps, we made three contributions in this paper. First, we propose an ontology for the cybersecurity education domain for students and novice learners. Second, we develop AISecKG, a triple dataset with cybersecurity-related entities and relations as defined by the ontology. This dataset can be used to construct knowledge graphs to teach cybersecurity and promote cognitive learning. It can also be used to build downstream applications like recommendation systems or self-learning question-answering systems for students. The dataset would also help identify malicious named entities and their probable impact. Third, using this dataset, we show a downstream application to extract custom-named entities from texts and educational material on cybersecurity."
    ],
    "paper": null,
    "introduced_date": "2023-03-30",
    "warning": null,
    "modalities": [
      "Texts"
    ],
    "tasks": [
      {
        "task": "Knowledge Graphs",
        "url": "https://paperswithcode.com/task/knowledge-graphs"
      },
      {
        "task": "NER",
        "url": "https://paperswithcode.com/task/cg"
      },
      {
        "task": "Ontology Matching",
        "url": "https://paperswithcode.com/task/ontology-matching"
      }
    ],
    "languages": [
      "English"
    ],
    "variants": [
      "AISECKG"
    ],
    "num_papers": 1,
    "data_loaders": [
      {
        "url": "https://github.com/garima0106/AISecKG-cybersecurity-dataset",
        "repo": "https://github.com/garima0106/AISecKG-cybersecurity-dataset",
        "frameworks": [
          "pytorch"
        ]
      }
    ]
  },
  {
    "url": "https://paperswithcode.com/dataset/edge-iiotset",
    "name": "EDGE-IIOTSET",
    "full_name": "A NEW COMPREHENSIVE REALISTIC CYBER SECURITY DATASET OF IOT AND IIOT APPLICATIONS: CENTRALIZED AND FEDERATED LEARNING",
    "homepage": "https://ieee-dataport.org/documents/edge-iiotset-new-comprehensive-realistic-cyber-security-dataset-iot-and-iiot-applications",
    "description": [
      "ABSTRACT",
      "In this project, we propose a new comprehensive realistic cyber security dataset of IoT and IIoT applications, called Edge-IIoTset, which can be used by machine learning-based intrusion detection systems in two different modes, namely, centralized and federated learning. Specifically, the proposed testbed is organized into seven layers, including, Cloud Computing Layer, Network Functions Virtualization Layer, Blockchain Network Layer, Fog Computing Layer, Software-Defined Networking Layer, Edge Computing Layer, and IoT and IIoT Perception Layer. In each layer, we propose new emerging technologies that satisfy the key requirements of IoT and IIoT applications, such as, ThingsBoard IoT platform, OPNFV platform, Hyperledger Sawtooth, Digital twin, ONOS SDN controller, Mosquitto MQTT brokers, Modbus TCP/IP, ...etc. The IoT data are generated from various IoT devices (more than 10 types) such as Low-cost digital sensors for sensing temperature and humidity, Ultrasonic sensor, Water level detection sensor, pH Sensor Meter, Soil Moisture sensor, Heart Rate Sensor, Flame Sensor, ...etc.). However, we identify and analyze fourteen attacks related to IoT and IIoT connectivity protocols, which are categorized into five threats, including, DoS/DDoS attacks, Information gathering, Man in the middle attacks, Injection attacks, and Malware attacks. In addition, we extract features obtained from different sources, including alerts, system resources, logs, network traffic, and propose new 61 features with high correlations from 1176 found features. After processing and analyzing the proposed realistic cyber security dataset, we provide a primary exploratory data analysis and evaluate the performance of machine learning approaches (i.e., traditional machine learning as well as deep learning) in both centralized and federated learning modes.",
      "Instructions:",
      "Great news! The Edge-IIoT dataset has been featured as a \"Document in the top 1% of Web of Science.\" This indicates that it is ranked within the top 1% of all publications indexed by the Web of Science (WoS) in terms of citations and impact.",
      "Please kindly visit kaggle link for the updates: https://www.kaggle.com/datasets/mohamedamineferrag/edgeiiotset-cyber-sec...",
      "Free use of the Edge-IIoTset dataset for academic research purposes is hereby granted in perpetuity. Use for commercial purposes is allowable after asking the leader author, Dr Mohamed Amine Ferrag, who has asserted his right under the Copyright.",
      "The details of the Edge-IIoT dataset were published in following the paper. For the academic/public use of these datasets, the authors have to cities the following paper:",
      "Mohamed Amine Ferrag, Othmane Friha, Djallel Hamouda, Leandros Maglaras, Helge Janicke, \"Edge-IIoTset: A New Comprehensive Realistic Cyber Security Dataset of IoT and IIoT Applications for Centralized and Federated Learning\", IEEE Access, April 2022 (IF: 3.37), DOI: 10.1109/ACCESS.2022.3165809",
      "Link to paper : https://ieeexplore.ieee.org/document/9751703",
      "********************************************",
      "The directories of the Edge-IIoTset dataset include the following:",
      "\u2022File 1 (Normal traffic)",
      "-File 1.1 (Distance): This file includes two documents, namely, Distance.csv and Distance.pcap. The IoT sensor (Ultrasonic sensor) is used to capture the IoT data.",
      "-File 1.2 (Flame_Sensor): This file includes two documents, namely, Flame_Sensor.csv and Flame_Sensor.pcap. The IoT sensor (Flame Sensor) is used to capture the IoT data.",
      "-File 1.3 (Heart_Rate): This file includes two documents, namely, Flame_Sensor.csv and Flame_Sensor.pcap. The IoT sensor (Flame Sensor) is used to capture the IoT data.",
      "-File 1.4 (IR_Receiver): This file includes two documents, namely, IR_Receiver.csv and IR_Receiver.pcap. The IoT sensor (IR (Infrared) Receiver Sensor) is used to capture the IoT data.",
      "-File 1.5 (Modbus): This file includes two documents, namely, Modbus.csv and Modbus.pcap. The IoT sensor (Modbus Sensor) is used to capture the IoT data.",
      "-File 1.6 (phValue): This file includes two documents, namely, phValue.csv and phValue.pcap. The IoT sensor (pH-sensor PH-4502C) is used to capture the IoT data.",
      "-File 1.7 (Soil_Moisture): This file includes two documents, namely, Soil_Moisture.csv and Soil_Moisture.pcap. The IoT sensor (Soil Moisture Sensor v1.2) is used to capture the IoT data.",
      "-File 1.8 (Sound_Sensor): This file includes two documents, namely, Sound_Sensor.csv and Sound_Sensor.pcap. The IoT sensor (LM393 Sound Detection Sensor) is used to capture the IoT data.",
      "-File 1.9 (Temperature_and_Humidity): This file includes two documents, namely, Temperature_and_Humidity.csv and Temperature_and_Humidity.pcap. The IoT sensor (DHT11 Sensor) is used to capture the IoT data.",
      "-File 1.10 (Water_Level): This file includes two documents, namely, Water_Level.csv and Water_Level.pcap. The IoT sensor (Water sensor) is used to capture the IoT data.",
      "\u2022File 2 (Attack traffic):",
      "-File 2.1 (Attack traffic (CSV files)): This file includes 13 documents, namely, Backdoor_attack.csv, DDoS_HTTP_Flood_attack.csv, DDoS_ICMP_Flood_attack.csv, DDoS_TCP_SYN_Flood_attack.csv, DDoS_UDP_Flood_attack.csv, MITM_attack.csv, OS_Fingerprinting_attack.csv, Password_attack.csv, Port_Scanning_attack.csv, Ransomware_attack.csv, SQL_injection_attack.csv, Uploading_attack.csv, Vulnerability_scanner_attack.csv, XSS_attack.csv. Each document is specific for each attack.",
      "-File 2.2 (Attack traffic (PCAP files)): This file includes 13 documents, namely, Backdoor_attack.pcap, DDoS_HTTP_Flood_attack.pcap, DDoS_ICMP_Flood_attack.pcap, DDoS_TCP_SYN_Flood_attack.pcap, DDoS_UDP_Flood_attack.pcap, MITM_attack.pcap, OS_Fingerprinting_attack.pcap, Password_attack.pcap, Port_Scanning_attack.pcap, Ransomware_attack.pcap, SQL_injection_attack.pcap, Uploading_attack.pcap, Vulnerability_scanner_attack.pcap, XSS_attack.pcap. Each document is specific for each attack.",
      "\u2022File 3 (Selected dataset for ML and DL):",
      "-File 3.1 (DNN-EdgeIIoT-dataset): This file contains a selected dataset for the use of evaluating deep learning-based intrusion detection systems.",
      "-File 3.2 (ML-EdgeIIoT-dataset): This file contains a selected dataset for the use of evaluating traditional machine learning-based intrusion detection systems.",
      "********************************************",
      "Step 1: Downloading The Edge-IIoTset dataset From the Kaggle platform",
      "from google.colab import files",
      "!pip install -q kaggle",
      "files.upload()",
      "!mkdir ~/.kaggle",
      "!cp kaggle.json ~/.kaggle/",
      "!chmod 600 ~/.kaggle/kaggle.json",
      "!kaggle datasets download -d mohamedamineferrag/edgeiiotset-cyber-security-dataset-of-iot-iiot -f \"Edge-IIoTset dataset/Selected dataset for ML and DL/DNN-EdgeIIoT-dataset.csv\"",
      "!unzip DNN-EdgeIIoT-dataset.csv.zip",
      "!rm DNN-EdgeIIoT-dataset.csv.zip",
      "Step 2: Reading the Datasets' CSV file to a Pandas DataFrame:",
      "import pandas as pd",
      "import numpy as np",
      "df = pd.read_csv('DNN-EdgeIIoT-dataset.csv', low_memory=False)",
      "Step 3 : Exploring some of the DataFrame's contents:",
      "df.head(5)",
      "print(df['Attack_type'].value_counts())",
      "Step 4: Dropping data (Columns, duplicated rows, NAN, Null..):",
      "from sklearn.utils import shuffle",
      "drop_columns = [\"frame.time\", \"ip.src_host\", \"ip.dst_host\", \"arp.src.proto_ipv4\",\"arp.dst.proto_ipv4\",",
      "\"http.file_data\",\"http.request.full_uri\",\"icmp.transmit_timestamp\",",
      "\"http.request.uri.query\", \"tcp.options\",\"tcp.payload\",\"tcp.srcport\",",
      "\"tcp.dstport\", \"udp.port\", \"mqtt.msg\"]",
      "df.drop(drop_columns, axis=1, inplace=True)",
      "df.dropna(axis=0, how='any', inplace=True)",
      "df.drop_duplicates(subset=None, keep=\"first\", inplace=True)",
      "df = shuffle(df)",
      "df.isna().sum()",
      "print(df['Attack_type'].value_counts())",
      "Step 5: Categorical data encoding (Dummy Encoding):",
      "import numpy as np",
      "from sklearn.model_selection import train_test_split",
      "from sklearn.preprocessing import StandardScaler",
      "from sklearn import preprocessing",
      "def encode_text_dummy(df, name):",
      "dummies = pd.get_dummies(df[name])",
      "for x in dummies.columns:",
      "dummy_name = f\"{name}-{x}\"",
      "df[dummy_name] = dummies[x]",
      "df.drop(name, axis=1, inplace=True)",
      "encode_text_dummy(df,'http.request.method')",
      "encode_text_dummy(df,'http.referer')",
      "encode_text_dummy(df,\"http.request.version\")",
      "encode_text_dummy(df,\"dns.qry.name.len\")",
      "encode_text_dummy(df,\"mqtt.conack.flags\")",
      "encode_text_dummy(df,\"mqtt.protoname\")",
      "encode_text_dummy(df,\"mqtt.topic\")",
      "Step 6: Creation of the preprocessed dataset",
      "df.to_csv('preprocessed_DNN.csv', encoding='utf-8')",
      "********************************************",
      "For more information about the dataset, please contact the lead author of this project, Dr Mohamed Amine Ferrag, on his email: mohamed.amine.ferrag@gmail.com",
      "More information about Dr. Mohamed Amine Ferrag is available at:",
      "https://www.linkedin.com/in/Mohamed-Amine-Ferrag",
      "https://dblp.uni-trier.de/pid/142/9937.html",
      "https://www.researchgate.net/profile/Mohamed_Amine_Ferrag",
      "https://scholar.google.fr/citations?user=IkPeqxMAAAAJ&hl=fr&oi=ao",
      "https://www.scopus.com/authid/detail.uri?authorId=56115001200",
      "https://publons.com/researcher/1322865/mohamed-amine-ferrag/",
      "https://orcid.org/0000-0002-0632-3172",
      "Last Updated: 27 Mar. 2023"
    ],
    "paper": null,
    "introduced_date": null,
    "warning": null,
    "modalities": [],
    "tasks": [
      {
        "task": "Intrusion Detection",
        "url": "https://paperswithcode.com/task/intrusion-detection"
      },
      {
        "task": "Network Intrusion Detection",
        "url": "https://paperswithcode.com/task/network-intrusion-detection"
      }
    ],
    "languages": [
      "English"
    ],
    "variants": [
      "EDGE-IIOTSET"
    ],
    "num_papers": 3,
    "data_loaders": []
  },
  {
    "url": "https://paperswithcode.com/dataset/ollabench-v-0-2",
    "name": "OllaBench v.0.2",
    "full_name": "OllaBench for Interdependent Cybersecurity v.0.2",
    "homepage": "https://github.com/Cybonto/OllaBench",
    "description": [
      "Large Language Models (LLMs) have the potential to enhance Agent-Based Modeling by better representing complex interdependent cybersecurity systems, improving cybersecurity threat modeling and risk management. Evaluating LLMs in this context is crucial for legal compliance and effective application development. Existing LLM evaluation frameworks often overlook the human factor and cognitive computing capabilities essential for interdependent cybersecurity. To address this gap, I propose OllaBench, a novel evaluation framework that assesses LLMs' accuracy, wastefulness, and consistency in answering scenario-based information security compliance and non-compliance questions."
    ],
    "paper": {
      "title": "Ollabench: Evaluating LLMs' Reasoning for Human-centric Interdependent Cybersecurity",
      "url": "https://paperswithcode.com/paper/ollabench-evaluating-llms-reasoning-for-human"
    },
    "introduced_date": "2024-06-11",
    "warning": null,
    "modalities": [
      "Texts"
    ],
    "tasks": [
      {
        "task": "Multiple-choice",
        "url": "https://paperswithcode.com/task/multiple-choice"
      },
      {
        "task": "Moral Scenarios",
        "url": "https://paperswithcode.com/task/moral-scenarios"
      },
      {
        "task": "Computer Security",
        "url": "https://paperswithcode.com/task/computer-security"
      }
    ],
    "languages": [
      "English"
    ],
    "variants": [
      "OllaBench v.0.2"
    ],
    "num_papers": 1,
    "data_loaders": []
  },
  {
    "url": "https://paperswithcode.com/dataset/arinc-429-voltage-data",
    "name": "ARINC 429 Voltage Data",
    "full_name": "",
    "homepage": "https://testscience.org/arinc/",
    "description": [
      "This page contains ARINC 429 message data recorded from the hardware-in-a-loop simulator. These messages were recorded using a SIGLENT SDS2204X Plus oscilloscope sampling at 20 MHz. The intent of this data is to enable cybersecurity research and development for ARINC 429 by providing detailed message data from multiple hardware sources.",
      "The dataset consists of three csv files of ARINC 429 messages along with a data dictionary markdown file. The zip file is 550MB and each csv file is approximately 1.5GB. The csv filenames indicate which transmitter the messages were being sent from, with the EGPWS representing a \u201cvalid\u201d transmitter while the RTX and AltaDT both represent adversarial transmitters."
    ],
    "paper": {
      "title": "ARINC 429 Cyber-vulnerabilities and Voltage Data in a Hardware-in-the-Loop Simulator",
      "url": "https://paperswithcode.com/paper/arinc-429-cyber-vulnerabilities-and-voltage"
    },
    "introduced_date": "2024-08-29",
    "warning": null,
    "modalities": [
      "Time series"
    ],
    "tasks": [
      {
        "task": "Intrusion Detection",
        "url": "https://paperswithcode.com/task/intrusion-detection"
      }
    ],
    "languages": [
      "English"
    ],
    "variants": [
      "ARINC 429 Voltage Data"
    ],
    "num_papers": 1,
    "data_loaders": []
  },
  {
    "url": "https://paperswithcode.com/dataset/cic-iomt-dataset-2024",
    "name": "CIC IoMT dataset 2024",
    "full_name": "",
    "homepage": "https://www.unb.ca/cic/datasets/iomt-dataset-2024.html",
    "description": [
      "The **CICIoMT2024 dataset** is a comprehensive dataset designed for cybersecurity research focused on the Internet of Medical Things (IoMT). Developed by the Canadian Institute for Cybersecurity, it simulates realistic IoMT network traffic, representing the diverse and evolving threats faced by connected healthcare devices. The dataset comprises network traffic data from various IoMT devices, with labeled instances for 18 distinct types of cyberattacks, alongside benign traffic data.",
      "Each cyberattack type is meticulously crafted to reflect common and advanced threats, such as Distributed Denial of Service (DDoS), ransomware, man-in-the-middle attacks, and malware injections. With a balanced mix of attacks and benign instances, CICIoMT2024 enables robust training and testing for various cybersecurity models.",
      "The CICIoMT2024 dataset\u2019s detailed packet-level information and multi-class labels make it ideal for developing and evaluating machine learning and deep learning algorithms. Its design emphasizes real-world application, making it a valuable resource for researchers aiming to enhance IoMT security, protect patient data, and ensure the resilience of medical networks against cyber threats."
    ],
    "paper": null,
    "introduced_date": null,
    "warning": null,
    "modalities": [],
    "tasks": [],
    "languages": [],
    "variants": [
      "CIC IoMT dataset 2024"
    ],
    "num_papers": 0,
    "data_loaders": []
  },
  {
    "url": "https://paperswithcode.com/dataset/cybench",
    "name": "Cybench",
    "full_name": "",
    "homepage": "https://cybench.github.io/",
    "description": [
      "Language Model (LM) agents for cybersecurity that are capable of autonomously identifying vulnerabilities and executing exploits have potential to cause real-world impact. Policymakers, model providers, and researchers in the AI and cybersecurity communities are interested in quantifying the capabilities of such agents to help mitigate cyberrisk and investigate opportunities for penetration testing. Toward that end, we introduce Cybench, a framework for specifying cybersecurity tasks and evaluating agents on those tasks. We include 40 professional-level Capture the Flag (CTF) tasks from 4 distinct CTF competitions, chosen to be recent, meaningful, and spanning a wide range of difficulties. Each task includes its own description, starter files, and is initialized in an environment where an agent can execute commands and observe outputs. Since many tasks are beyond the capabilities of existing LM agents, we introduce subtasks for each task, which break down a task into intermediary steps for a more detailed evaluation. To evaluate agent capabilities, we construct a cybersecurity agent and evaluate 8 models: GPT-4o, OpenAI o1-preview, Claude 3 Opus, Claude 3.5 Sonnet, Mixtral 8x22b Instruct, Gemini 1.5 Pro, Llama 3 70B Chat, and Llama 3.1 405B Instruct. For the top performing models (GPT-4o and Claude 3.5 Sonnet), we further investigate performance across 4 agent scaffolds (structed bash, action-only, pseudoterminal, and web search). Without subtask guidance, agents leveraging Claude 3.5 Sonnet, GPT-4o, OpenAI o1-preview, and Claude 3 Opus successfully solved complete tasks that took human teams up to 11 minutes to solve. In comparison, the most difficult task took human teams 24 hours and 54 minutes to solve. All code and data are publicly available at https://cybench.github.io/."
    ],
    "paper": {
      "title": "Cybench: A Framework for Evaluating Cybersecurity Capabilities and Risks of Language Models",
      "url": "https://paperswithcode.com/paper/cybench-a-framework-for-evaluating"
    },
    "introduced_date": "2024-08-15",
    "warning": null,
    "modalities": [],
    "tasks": [
      {
        "task": "",
        "url": "https://paperswithcode.com/task/task"
      }
    ],
    "languages": [],
    "variants": [
      "Cybench"
    ],
    "num_papers": 5,
    "data_loaders": []
  },
  {
    "url": "https://paperswithcode.com/dataset/cybersecurity-threat-detection",
    "name": "Cybersecurity Threat Detection",
    "full_name": "",
    "homepage": "https://globaltechnosol.com/case_studies/cybersecurity-threat-detection/",
    "description": [
      "Problem Statement",
      "<a href=\"https://globaltechnosol.com/case_studies/Cybersecurity-Threat-Detection/\" target=\"_blank\">\ud83d\udc49 Download the case studies here</a>",
      "Organizations face an increasing number of sophisticated cybersecurity threats, including malware, phishing attacks, and unauthorized access. A financial institution experienced frequent attempts to breach its network, risking sensitive data and regulatory compliance. Traditional security measures were reactive and failed to detect threats in real time. The institution sought a proactive AI-driven solution to identify and prevent cybersecurity threats effectively.",
      "Challenge",
      "Developing an advanced threat detection system required addressing several challenges:",
      "Processing and analyzing large volumes of network traffic and user activity data in real time.",
      "Identifying new and evolving threats, such as zero-day vulnerabilities, with high accuracy.",
      "Minimizing false positives to ensure security teams could focus on genuine threats.",
      "Solution Provided",
      "An AI-powered threat detection system was developed using machine learning algorithms and advanced analytics. The solution was designed to:",
      "Continuously monitor network activity and user behavior to identify suspicious patterns.",
      "Detect and neutralize cybersecurity threats in real time, including malware and phishing attempts.",
      "Provide actionable insights to security teams for faster and more effective threat response.",
      "Development Steps",
      "Data Collection",
      "Collected network traffic logs, endpoint activity, and historical threat data to train machine learning models.",
      "Preprocessing",
      "Cleaned and standardized data, ensuring compatibility across diverse sources, and filtered out noise for accurate analysis.",
      "Model Development",
      "Developed machine learning algorithms for anomaly detection, behavioral analysis, and threat classification. Trained models on labeled datasets to recognize known threats and identify emerging attack patterns.",
      "Validation",
      "Tested the system against simulated and real-world threat scenarios to evaluate detection accuracy, response times, and reliability.",
      "Deployment",
      "Integrated the threat detection system into the institution\u2019s existing cybersecurity infrastructure, including firewalls, SIEM (Security Information and Event Management) tools, and endpoint protection",
      "Continuous Monitoring & Improvement",
      "Established a feedback loop to refine models using new threat data and adapt to evolving attack strategies.",
      "Results",
      "Enhanced Security Posture",
      "The system improved the institution\u2019s ability to detect and prevent cybersecurity threats proactively, strengthening its overall security framework.",
      "Reduced Incidence of Cyber Attacks",
      "Real-time detection and response significantly reduced the frequency and impact of successful cyber attacks.",
      "Improved Threat Response Times",
      "Automated threat identification and prioritization enabled security teams to respond faster and more effectively to potential breaches.",
      "Minimized False Positives",
      "Advanced algorithms reduced false alarms, allowing security teams to focus on genuine threats and improve efficiency.",
      "Scalable and Adaptive Solution",
      "The system adapted to new threats and scaled effortlessly to protect growing organizational networks and data."
    ],
    "paper": null,
    "introduced_date": null,
    "warning": null,
    "modalities": [],
    "tasks": [],
    "languages": [
      "English"
    ],
    "variants": [
      "Cybersecurity Threat Detection"
    ],
    "num_papers": 0,
    "data_loaders": []
  }
]
